{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = pickle.load(open(\\'../data/Data_test/*\\', \"rb\"), encoding=\\'latin1\\')'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data = pickle.load(open('../data/Data_test/*', \"rb\"), encoding='latin1')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "finding files: morphology and test data\n",
      "-----------------------------------------------\n",
      "morphology found     : \"morphology_dict.pickle\"\n",
      "number of test files is 12\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "save_figures = False\n",
    "file_ending = '.png'\n",
    "model_string = 'NMDA'\n",
    "\n",
    "dataset_folder = '../data'\n",
    "\n",
    "morphology_folder = os.path.join(dataset_folder, 'Morphology')\n",
    "test_data_folder  = os.path.join(dataset_folder, 'Data_test')\n",
    "\n",
    "morphology_filename      = os.path.join(morphology_folder, 'morphology_dict.pickle')\n",
    "test_files               = sorted(glob.glob(os.path.join(test_data_folder, '*_128_simulationRuns*_6_secDuration_*')))\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print('finding files: morphology and test data')\n",
    "print('-----------------------------------------------')\n",
    "print('morphology found     : \"%s\"' %(morphology_filename.split('/')[-1]))\n",
    "print('number of test files is %d' %(len(test_files)))\n",
    "print('-----------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% helper functions\n",
    "\n",
    "def dict2bin(row_inds_spike_times_map, num_segments, sim_duration_ms): # \n",
    "    \n",
    "    bin_spikes_matrix = np.zeros((num_segments, sim_duration_ms), dtype='bool') # creating a counter array\n",
    "    for row_ind in row_inds_spike_times_map.keys():\n",
    "        for spike_time in row_inds_spike_times_map[row_ind]:\n",
    "            bin_spikes_matrix[row_ind,spike_time] = 1.0\n",
    "    \n",
    "    return bin_spikes_matrix #matrix counter\n",
    "\n",
    "def parse_sim_experiment_file(sim_experiment_file):\n",
    "    \n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(\"loading file: '\" + sim_experiment_file.split(\"\\\\\")[-1] + \"'\")\n",
    "    loading_start_time = time.time()\n",
    "    experiment_dict = pickle.load(open(sim_experiment_file, \"rb\" ), encoding='latin1') # loading files\n",
    "    \n",
    "    # gather params\n",
    "    num_simulations = len(experiment_dict['Results']['listOfSingleSimulationDicts']) #128\n",
    "    num_segments    = len(experiment_dict['Params']['allSegmentsType']) #639\n",
    "    sim_duration_ms = experiment_dict['Params']['totalSimDurationInSec']*1000\n",
    "    num_ex_synapses  = 30000//num_segments\n",
    "    num_inh_synapses = 1700//num_segments\n",
    "    num_synapses = num_ex_synapses + num_inh_synapses ## WHY double the Synapse count????\n",
    "    \n",
    "    # collect X, y_spike, y_soma\n",
    "    X = np.zeros((num_synapses,sim_duration_ms,num_simulations), dtype='bool') #(48, 6000, 128)\n",
    "    y_spike = np.zeros((sim_duration_ms,num_simulations)) #(6000, 128)\n",
    "    y_soma  = np.zeros((sim_duration_ms,num_simulations)) # (6000, 128)\n",
    "    for k, sim_dict in enumerate(experiment_dict['Results']['listOfSingleSimulationDicts']):\n",
    "        X_ex  = dict2bin(sim_dict['exInputSpikeTimes'] , num_segments, sim_duration_ms)\n",
    "        X_inh = dict2bin(sim_dict['inhInputSpikeTimes'], num_segments, sim_duration_ms)\n",
    "        X[:,:,k] = np.vstack((X_ex,X_inh))\n",
    "        spike_times = (sim_dict['outputSpikeTimes'].astype(float) - 0.5).astype(int)\n",
    "        y_spike[spike_times,k] = 1.0\n",
    "        y_soma[:,k] = sim_dict['somaVoltageLowRes']\n",
    "\n",
    "    loading_duration_sec = time.time() - loading_start_time \n",
    "    print('loading took %.3f seconds' %(loading_duration_sec))\n",
    "    print('-----------------------------------------------------------------')\n",
    "\n",
    "    return X, y_spike, y_soma\n",
    "\n",
    "\n",
    "def parse_multiple_sim_experiment_files(sim_experiment_files):\n",
    "    \n",
    "    for k, sim_experiment_file in enumerate(sim_experiment_files):\n",
    "        X_curr, y_spike_curr, y_soma_curr = parse_sim_experiment_file(sim_experiment_file)\n",
    "        \n",
    "        if k == 0:\n",
    "            X       = X_curr\n",
    "            y_spike = y_spike_curr\n",
    "            y_soma  = y_soma_curr\n",
    "        else:\n",
    "            X       = np.dstack((X,X_curr))\n",
    "            y_spike = np.hstack((y_spike,y_spike_curr))\n",
    "            y_soma  = np.hstack((y_soma,y_soma_curr))\n",
    "            \n",
    "    return X, y_spike, y_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-15efc4b503bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading file: '\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloading_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexperiment_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loading files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('-----------------------------------------------------------------')\n",
    "print(\"loading file: '\" + test_files.split(\"\\\\\")[-1] + \"'\")\n",
    "loading_start_time = time.time()\n",
    "experiment_dict = pickle.load(open(test_files, \"rb\" ), encoding='latin1') # loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c730c5aae253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sim_duration_ms ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totalSimDurationInSec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_simulations ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'listOfSingleSimulationDicts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_segments    ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allSegmentsType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#639\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sim_duration_ms ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totalSimDurationInSec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_ex_synapses  ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print('sim_duration_ms =', experiment_dict['Params']['totalSimDurationInSec']*1000)\n",
    "print('num_simulations =', len(experiment_dict['Results']['listOfSingleSimulationDicts'])) #128\n",
    "print('num_segments    =', len(experiment_dict['Params']['allSegmentsType'])) #639\n",
    "print('sim_duration_ms =', experiment_dict['Params']['totalSimDurationInSec']*1000)\n",
    "print('num_ex_synapses  =', (30000*num_segments))\n",
    "print('num_inh_synapses =', (1700*num_segments))\n",
    "print('num_synapses =' ,num_ex_synapses + num_inh_synapses)\n",
    "X = np.zeros((num_synapses,sim_duration_ms,num_simulations), dtype='bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "loading testing files...\n",
      "-----------------------------------------------------------------\n",
      "loading file: '../data/Data_test/sim__saved_InputSpikes_DVTs__561_outSpikes__128_simulationRuns__6_secDuration__randomSeed_100520.p'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1278,6000) into shape (48,6000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e52a6105a4bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# load test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_spike_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_soma_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mparse_multiple_sim_experiment_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_soma_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_soma_test\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mv_threshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-77bdc3dd1a1b>\u001b[0m in \u001b[0;36mparse_multiple_sim_experiment_files\u001b[0;34m(sim_experiment_files)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_experiment_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_experiment_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mX_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_spike_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_soma_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_sim_experiment_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_experiment_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-77bdc3dd1a1b>\u001b[0m in \u001b[0;36mparse_sim_experiment_file\u001b[0;34m(sim_experiment_file)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mX_ex\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdict2bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exInputSpikeTimes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_duration_ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mX_inh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict2bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inhInputSpikeTimes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_duration_ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_inh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mspike_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msim_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputSpikeTimes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0my_spike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspike_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1278,6000) into shape (48,6000)"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% load test dataset\n",
    "\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('loading testing files...')\n",
    "test_file_loading_start_time = time.time()\n",
    "\n",
    "v_threshold = -55\n",
    "\n",
    "test_files = test_files[:3] # just load 3 files \n",
    "\n",
    "# load test data\n",
    "X_test , y_spike_test , y_soma_test  = parse_multiple_sim_experiment_files(test_files)\n",
    "y_soma_test[y_soma_test > v_threshold] = v_threshold\n",
    "\n",
    "test_file_loading_duration_min = (time.time() - test_file_loading_start_time)/60\n",
    "print('time took to load data is %.3f minutes' %(test_file_loading_duration_min))\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_soma_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% load morphology\n",
    "\n",
    "morphology_dict = pickle.load(open(morphology_filename, \"rb\" ), encoding='latin1')\n",
    "\n",
    "#lists of morphology\n",
    "\n",
    "allSectionsLength                  = morphology_dict['all_sections_length']\n",
    "allSections_DistFromSoma           = morphology_dict['all_sections_distance_from_soma']\n",
    "allSegmentsLength                  = morphology_dict['all_segments_length']\n",
    "allSegmentsType                    = morphology_dict['all_segments_type']\n",
    "allSegments_DistFromSoma           = morphology_dict['all_segments_distance_from_soma']\n",
    "allSegments_SectionDistFromSoma    = morphology_dict['all_segments_section_distance_from_soma']\n",
    "allSegments_SectionInd             = morphology_dict['all_segments_section_index']\n",
    "allSegments_seg_ind_within_sec_ind = morphology_dict['all_segments_segment_index_within_section_index']\n",
    "\n",
    "all_basal_section_coords  = morphology_dict['all_basal_section_coords']\n",
    "all_basal_segment_coords  = morphology_dict['all_basal_segment_coords']\n",
    "all_apical_section_coords = morphology_dict['all_apical_section_coords']\n",
    "all_apical_segment_coords = morphology_dict['all_apical_segment_coords']\n",
    "\n",
    "seg_ind_to_xyz_coords_map = {}\n",
    "seg_ind_to_sec_ind_map = {}\n",
    "for k in range(len(allSegmentsType)):\n",
    "    curr_segment_ind = allSegments_seg_ind_within_sec_ind[k]\n",
    "    if allSegmentsType[k] == 'basal':\n",
    "        curr_section_ind = allSegments_SectionInd[k]\n",
    "        seg_ind_to_xyz_coords_map[k] = all_basal_segment_coords[(curr_section_ind,curr_segment_ind)]\n",
    "        seg_ind_to_sec_ind_map[k] = ('basal', curr_section_ind)\n",
    "    elif allSegmentsType[k] == 'apical':\n",
    "        curr_section_ind = allSegments_SectionInd[k] - len(all_basal_section_coords)\n",
    "        seg_ind_to_xyz_coords_map[k] = all_apical_segment_coords[(curr_section_ind,curr_segment_ind)]\n",
    "        seg_ind_to_sec_ind_map[k] = ('apical', curr_section_ind)\n",
    "    else:\n",
    "        print('error!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basal = len([i for i in morphology_dict['all_segments_type'] if i == 'basal']) # 262\n",
    "apical = len([i for i in morphology_dict['all_segments_type'] if i == 'apical']) #377\n",
    "apical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_basal_segment_coords) + len(all_basal_section_coords) #346\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##%% load dendritic voltage traces of single simulation file\n",
    "\n",
    "sim_experiment_file = test_files[0]\n",
    "experiment_dict = pickle.load(open(sim_experiment_file, \"rb\" ), encoding='latin1')\n",
    "\n",
    "X_spikes, _, _ = parse_sim_experiment_file(sim_experiment_file)\n",
    "\n",
    "# gather params\n",
    "num_simulations = len(experiment_dict['Results']['listOfSingleSimulationDicts'])\n",
    "num_segments    = len(experiment_dict['Params']['allSegmentsType'])\n",
    "sim_duration_ms = experiment_dict['Params']['totalSimDurationInSec']*1000\n",
    "\n",
    "# collect X, y_spike, y_soma\n",
    "sim_dict = experiment_dict['Results']['listOfSingleSimulationDicts'][0]\n",
    "\n",
    "t_LR = sim_dict['recordingTimeLowRes']\n",
    "t_HR = sim_dict['recordingTimeHighRes']\n",
    "y_soma_LR  = np.zeros((sim_duration_ms,num_simulations))\n",
    "y_nexus_LR = np.zeros((sim_duration_ms,num_simulations))\n",
    "y_soma_HR  = np.zeros((sim_dict['somaVoltageHighRes'].shape[0],num_simulations))\n",
    "y_nexus_HR = np.zeros((sim_dict['nexusVoltageHighRes'].shape[0],num_simulations))\n",
    "\n",
    "y_DVTs  = np.zeros((num_segments,sim_duration_ms,num_simulations), dtype=np.float16)\n",
    "\n",
    "# go over all simulations in the experiment and collect their results\n",
    "for k, sim_dict in enumerate(experiment_dict['Results']['listOfSingleSimulationDicts']):\n",
    "    y_nexus_LR[:,k] = sim_dict['nexusVoltageLowRes']\n",
    "    y_soma_LR[:,k] = sim_dict['somaVoltageLowRes']    \n",
    "    y_nexus_HR[:,k] = sim_dict['nexusVoltageHighRes']\n",
    "    y_soma_HR[:,k] = sim_dict['somaVoltageHighRes']    \n",
    "    y_DVTs[:,:,k] = sim_dict['dendriticVoltagesLowRes']\n",
    "\n",
    "    output_spike_times = np.int32(sim_dict['outputSpikeTimes'])\n",
    "    # put \"voltage spikes\" in low res\n",
    "    y_soma_LR[output_spike_times,k] = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dict['Results']['listOfSingleSimulationDicts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#%% show some colored DVTs with trace colors colorcoded with morphology segments\n",
    "# also show soma and nexus voltage traces at the bottom\n",
    "\n",
    "time_point_ranges_options = [[2800,3200],[2600,3400]]\n",
    "\n",
    "# select random simulation to display\n",
    "num_spikes_per_sim = (y_soma_LR > 20).sum(axis=0)\n",
    "possible_simulations = np.nonzero(np.logical_and(num_spikes_per_sim >= 5, num_spikes_per_sim <= 30))[0]\n",
    "random_simulation = np.random.choice(possible_simulations, size=1)[0]\n",
    "\n",
    "print('random_simulation = %d' %(random_simulation))\n",
    "\n",
    "for time_points_ranges in time_point_ranges_options:\n",
    "    # choose time points to display\n",
    "    # time_points_ranges = [2800,3200]\n",
    "    width_mult_factor = 1.2\n",
    "\n",
    "    duration_ms = time_points_ranges[1] - time_points_ranges[0]\n",
    "\n",
    "    section_index      = np.array(experiment_dict['Params']['allSegments_SectionInd'])\n",
    "    distance_from_soma = np.array(experiment_dict['Params']['allSegments_SectionDistFromSoma'])\n",
    "    is_basal           = np.array([x == 'basal' for x in experiment_dict['Params']['allSegmentsType']])\n",
    "\n",
    "    dend_colors = section_index*20 + distance_from_soma\n",
    "    dend_colors = dend_colors / dend_colors.max()\n",
    "\n",
    "    all_seg_inds = seg_ind_to_xyz_coords_map.keys()\n",
    "    colors = plt.cm.jet(dend_colors)\n",
    "\n",
    "    # assemble the colors for each dendritic segment\n",
    "    colors_per_segment = {}\n",
    "    for seg_ind in all_seg_inds:\n",
    "        colors_per_segment[seg_ind] = colors[seg_ind]\n",
    "\n",
    "    fig = plt.figure(figsize=(32,15))\n",
    "    fig.subplots_adjust(left=0.01,right=0.99,top=0.99,bottom=0.01,hspace=0.01, wspace=0.2)\n",
    "\n",
    "    ax1 = plt.subplot2grid((1, 4), (0, 0), colspan=1)\n",
    "    ax2 = plt.subplot2grid((1, 4), (0, 1), colspan=3)\n",
    "\n",
    "    # plot the cell morphology\n",
    "    ax1.set_axis_off()\n",
    "    for key in all_seg_inds:\n",
    "        seg_color = colors_per_segment[key]\n",
    "        seg_line_width = width_mult_factor*np.array(seg_ind_to_xyz_coords_map[key]['d']).mean()\n",
    "        seg_x_coords = seg_ind_to_xyz_coords_map[key]['x']\n",
    "        seg_y_coords = seg_ind_to_xyz_coords_map[key]['y']\n",
    "\n",
    "        ax1.plot(seg_x_coords,seg_y_coords,lw=seg_line_width,color=seg_color)\n",
    "\n",
    "    # add black soma    \n",
    "    ax1.scatter(x=45.5,y=19.8,s=120,c='k')\n",
    "    ax1.set_xlim(-180,235)\n",
    "    ax1.set_ylim(-210,1200)\n",
    "\n",
    "    # plot the DVTs\n",
    "    dend_colors = section_index*20 + distance_from_soma\n",
    "    dend_colors = dend_colors / dend_colors.max()\n",
    "    sorted_according_to_colors = np.argsort(dend_colors)\n",
    "    delta_voltage = 700.0 / sorted_according_to_colors.shape[0]\n",
    "    for k in sorted_according_to_colors:\n",
    "        ax2.plot(t_LR, 150+k*delta_voltage+y_DVTs[k,:,random_simulation].T,c=colors[k], alpha=0.55)\n",
    "\n",
    "    # plot the soma and nexus traces\n",
    "    ax2.plot(t_HR[:], 2.3*y_soma_HR[:,random_simulation].T, c='darkblue', lw=2.4)\n",
    "    ax2.plot(t_HR[:], 2.3*y_nexus_HR[:,random_simulation].T, c='red', lw=2.4)\n",
    "    ax2.set_xlim(time_points_ranges[0],time_points_ranges[1]);\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    fig.patch.set_facecolor('black')\n",
    "    #fig.patch.set_facecolor('0.12')\n",
    "    \n",
    "    if save_figures:\n",
    "        figure_name = '%s__DVT_%d_ms_%d' %(model_string, duration_ms, np.random.randint(20))\n",
    "        fig.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% show input spikes (X) and output somatic voltages\n",
    "\n",
    "num_spikes_per_sim = y_spike_test.sum(axis=0)\n",
    "possible_simulations = np.nonzero(np.logical_and(num_spikes_per_sim >= 3, num_spikes_per_sim <= 30))[0]\n",
    "random_simulation = np.random.choice(possible_simulations, size=1)[0]\n",
    "\n",
    "num_synapses = X_test.shape[0]\n",
    "num_ex_synapses  = int(num_synapses/2)\n",
    "num_inh_synapses = int(num_synapses/2)\n",
    "\n",
    "# covert binary matrix to dict representation\n",
    "all_presynaptic_spikes_bin = X_test[:,:,random_simulation]\n",
    "\n",
    "exc_presynaptic_spikes = X_test[:num_ex_synapses,:,random_simulation].T\n",
    "inh_presynaptic_spikes = X_test[num_ex_synapses:,:,random_simulation].T\n",
    "\n",
    "#ex_presynaptic_spikes = X_test[random_simulation,:num_ex_synapses,:]\n",
    "soma_voltage_trace = y_soma_test[:,random_simulation]\n",
    "soma_voltage_trace[soma_voltage_trace > -30] = 30 # fix spikes height (that occurs due to low resolution temporal sampling)\n",
    "\n",
    "# for raster plot (scatter)\n",
    "exc_syn_activation_time, exc_syn_activation_index = np.nonzero(exc_presynaptic_spikes)\n",
    "exc_syn_activation_time = exc_syn_activation_time / 1000.0\n",
    "\n",
    "inh_syn_activation_time, inh_syn_activation_index = np.nonzero(inh_presynaptic_spikes)\n",
    "inh_syn_activation_index = inh_syn_activation_index + num_ex_synapses\n",
    "inh_syn_activation_time = inh_syn_activation_time / 1000.0\n",
    "\n",
    "\n",
    "exc_instantaneous_firing_rate = exc_presynaptic_spikes.sum(axis=1)\n",
    "inh_instantaneous_firing_rate = inh_presynaptic_spikes.sum(axis=1)\n",
    "\n",
    "tau = 10\n",
    "exc_instantaneous_firing_rate = signal.convolve(exc_instantaneous_firing_rate   , (1.0/tau)*np.ones((tau,)), mode='same')\n",
    "inh_instantaneous_firing_rate = signal.convolve(inh_instantaneous_firing_rate   , (1.0/tau)*np.ones((tau,)), mode='same')\n",
    "\n",
    "sim_duration_sec = sim_duration_ms / 1000.0\n",
    "time_in_sec = np.arange(sim_duration_ms) / 1000.0\n",
    "\n",
    "\n",
    "xytick_labels_fontsize = 16\n",
    "title_fontsize = 30\n",
    "xylabels_fontsize = 22\n",
    "legend_fontsize = 26\n",
    "\n",
    "fig = plt.figure(figsize=(25,18));\n",
    "gs = gridspec.GridSpec(4,1)\n",
    "gs.update(left=0.05, right=0.97, bottom=0.05, top=0.97, hspace=0.12)\n",
    "ax0 = plt.subplot(gs[0:2,0])\n",
    "ax1 = plt.subplot(gs[2,0])\n",
    "ax2 = plt.subplot(gs[3,0])\n",
    "\n",
    "ax0.scatter(exc_syn_activation_time, exc_syn_activation_index, s=2, c='r')\n",
    "ax0.scatter(inh_syn_activation_time, inh_syn_activation_index, s=2, c='b')\n",
    "#ax0.set_axis_off()\n",
    "ax0.set_xlim(0,sim_duration_sec-0.01)\n",
    "ax0.set_ylabel('synapse index \\n', fontsize=xylabels_fontsize)\n",
    "ax0.grid('off')\n",
    "ax0.set_yticks([])\n",
    "ax0.set_xticks([])\n",
    "\n",
    "ax1.plot(time_in_sec, exc_instantaneous_firing_rate, c='r')\n",
    "ax1.plot(time_in_sec, inh_instantaneous_firing_rate, c='b')\n",
    "ax1.set_xlim(0,sim_duration_sec)\n",
    "ax1.set_ylabel('total number of input spikes\\n per milisecond', fontsize=xylabels_fontsize);\n",
    "ax1.legend(['excitation', 'inhibition'], fontsize=legend_fontsize, loc='upper left', ncol=2);\n",
    "\n",
    "ax2.plot(time_in_sec, soma_voltage_trace, c='k')\n",
    "ax2.set_xlim(0,sim_duration_sec)\n",
    "ax2.set_ylabel('Soma Voltage [mV]', fontsize=xylabels_fontsize);\n",
    "ax2.set_xlabel('Time [sec]', fontsize=xylabels_fontsize);\n",
    "\n",
    "if save_figures:\n",
    "    figure_name = '%s__input_output_%d' %(model_string, np.random.randint(20))\n",
    "    fig.savefig(output_figures_dir + figure_name + file_ending, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f19acf6f74a7eb80785c6028b5d0046357fb08ccf452a8c71704de342991f470"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
